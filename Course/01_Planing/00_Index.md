# Data Science

## ‚è≥ Estimado con 7h/semana

| Etapa                                          | Contenido clave                                                              | Tiempo aproximado |
| ---------------------------------------------- | ---------------------------------------------------------------------------- | ----------------- |
| **1. Fundamentos de Python para Data Science** | Sintaxis, estructuras, librer√≠as (NumPy, Pandas, Matplotlib)                 | 2‚Äì3 meses         |
| **2. Matem√°ticas y estad√≠stica aplicada**      | Probabilidad, estad√≠stica descriptiva, √°lgebra lineal b√°sica, distribuciones | 3‚Äì4 meses         |
| **3. Limpieza y preparaci√≥n de datos**         | Data wrangling, outliers, feature engineering b√°sico                         | 1.5‚Äì2 meses       |
| **4. An√°lisis exploratorio de datos (EDA)**    | Visualizaciones, correlaciones, hip√≥tesis                                    | 1.5 meses         |
| **5. Machine Learning cl√°sico**                | Regresi√≥n, clasificaci√≥n, clustering, validaci√≥n cruzada                     | 3‚Äì4 meses         |
| **6. Deep Learning**                           | Redes neuronales, CNN, RNN, optimizaci√≥n, regularizaci√≥n                     | 4‚Äì5 meses         |
| **7. Interpretabilidad y explicaciones**       | SHAP, LIME, importancia de variables                                         | 1 mes             |
| **8. Producci√≥n y despliegue**                 | MLflow, APIs, Docker, pipelines                                              | 3‚Äì4 meses         |
| **9. Proyecto final integrador**               | End-to-end con dataset real                                                  | 2‚Äì3 meses         |

---

### üìå Total estimado

* **Ritmo de 7h/semana:** 24‚Äì30 meses para cubrirlo todo con profundidad
* **Si quieres solo perfil de Data Scientist con ML** (sin tanto despliegue ni DL): 12‚Äì15 meses
* Puedes acortar si en vacaciones o fines de semana extras subes el ritmo.

---

Con este ritmo, lo ideal ser√≠a ir **haciendo mini-proyectos desde el mes 2** para que desde temprano tengas portafolio, porque eso acelera mucho la b√∫squeda de trabajo.


---

## Esquema de ciclo de estudio

Perfecto, aqu√≠ tienes el esquema del ciclo completo para un **Data Scientist especializado en ML/DL**, con todo el flujo que manejar√≠as t√∫:

---

**1. Obtenci√≥n de datos**

* Conectar a bases de datos SQL/NoSQL
* Extraer datos de APIs, web scraping o archivos planos (CSV, Excel, JSON, Parquet)
* Validar calidad y formato de los datos

---

**2. Limpieza y preparaci√≥n de datos** *(Data Wrangling)*

* Manejo de valores faltantes y outliers
* Conversi√≥n de tipos de datos (categor√≠as, fechas, num√©ricos)
* Normalizaci√≥n y estandarizaci√≥n de variables
* Detecci√≥n de datos inconsistentes o duplicados

---

**3. An√°lisis exploratorio (EDA)**

* Visualizaci√≥n de distribuciones, correlaciones y tendencias
* An√°lisis estad√≠stico y pruebas de hip√≥tesis
* Descubrimiento de patrones y posibles relaciones
* Identificaci√≥n de sesgos o desbalance en las clases

---

**4. Ingenier√≠a de caracter√≠sticas (Feature Engineering)**

* Creaci√≥n de nuevas variables derivadas
* Selecci√≥n de variables relevantes (Feature Selection)
* Reducci√≥n de dimensionalidad (PCA, t-SNE)
* Codificaci√≥n de variables categ√≥ricas (One-Hot, Label Encoding)

---

**5. Entrenamiento de modelos (ML/DL)**

* Modelos cl√°sicos (regresi√≥n, √°rboles, boosting)
* Redes neuronales (MLP, CNN, RNN, Transformers)
* Optimizaci√≥n de hiperpar√°metros (Grid Search, Bayesian Optimization)
* Uso de GPU para acelerar entrenamiento

---

**6. Evaluaci√≥n y validaci√≥n**

* Comparar m√©tricas clave (precisi√≥n, recall, RMSE, etc.)
* Validaci√≥n cruzada y separaci√≥n train/test
* An√°lisis de errores y ajuste fino del modelo

---

**7. Interpretabilidad y explicaciones**

* SHAP, LIME para explicar decisiones
* Visualizaci√≥n de importancia de variables
* Reportes para stakeholders

---

**8. Despliegue del modelo**

* APIs con FastAPI o Flask
* Aplicaciones web interactivas con Streamlit o Dash
* Contenerizaci√≥n con Docker
* Monitoreo de rendimiento en producci√≥n

---

**9. Mantenimiento y mejora continua**

* Retraining con nuevos datos
* Monitoreo de drift de datos y degradaci√≥n de modelos
* Optimizaci√≥n de recursos en la nube


