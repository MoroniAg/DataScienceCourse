# **Recurrent Neural Networks (RNNs)** â€“ secuencias y datos temporales.

### ğŸ§  **Â¿QuÃ© es una RNN?**

ImaginÃ¡ que estÃ¡s leyendo un libro, pero con una condiciÃ³n:

> Cada vez que lees una palabra nueva, puedes recordar lo que leÃ­ste antes para entender mejor lo que sigue.
> 

ğŸ’¬ Por ejemplo, si te digo:

- â€œEl perro ladrÃ³ porque estabaâ€¦â€
- Vos ya intuÃ­s que la siguiente palabra podrÃ­a ser *asustado*, *hambriento*, o *feliz*.
    
    Pero no podrÃ­as adivinarlo sin **recordar lo anterior**.
    

Eso es lo que hace una **RNN (Recurrent Neural Network)**:

ğŸ” *â€œleeâ€ datos secuenciales paso a paso, y en cada paso guarda una pequeÃ±a memoria del pasado.*

---

### âš™ï¸ Â¿CÃ³mo se diferencia de una MLP?

| SituaciÃ³n | MLP | RNN |
| --- | --- | --- |
| Lee todo a la vez | âœ… SÃ­ | ğŸš« No, lee paso por paso |
| Recuerda pasos anteriores | ğŸš« No | âœ… SÃ­ |
| Ideal para texto/audio | ğŸ˜’ No | ğŸ˜ SÃ­ |

---

### ğŸ§  MetÃ¡fora rÃ¡pida:

> Una MLP es como un turista con amnesia: solo ve lo que tiene enfrente.
> 
> 
> Una RNN es como un lector atento: recuerda lo que ya leyÃ³.
> 

---

### ğŸ› ï¸ Â¿Para quÃ© sirve una RNN?

- TraducciÃ³n de idiomas
- PredicciÃ³n de texto (*autocompletado*)
- AnÃ¡lisis de sentimiento
- Reconocimiento de voz
- PredicciÃ³n de series de tiempo (ventas, clima, etc.)

## ğŸ§  PARTE 1 â€” Â¿CÃ³mo funciona internamente una RNN?

Vamos a meternos en el flujo de datos, **paso por paso**, con la siguiente idea base:

> Una RNN recibe una secuencia de datos y recuerda lo anterior para influir en lo que hace ahora.
> 

---

### ğŸ“¦ ImaginÃ¡ esta secuencia de palabras:

**â€œEl clima estÃ¡ muy...â€**

Y la red debe predecir la prÃ³xima palabra. Cada palabra se procesa **una a una**:

```
Timestep 1 â†’ â€œElâ€
Timestep 2 â†’ â€œclimaâ€
Timestep 3 â†’ â€œestÃ¡â€
Timestep 4 â†’ â€œmuyâ€
```

---

### ğŸ” En cada paso ocurren **tres cosas clave**:

1. **Se recibe un dato de entrada**
    
    (por ejemplo, la palabra â€œclimaâ€ convertida en un vector numÃ©rico)
    
2. **Se recibe lo que la red â€œrecuerdaâ€ del paso anterior**
    
    (esto se llama *estado oculto* o *hidden state*)
    
3. **Se genera una salida**
    
    (por ejemplo, una predicciÃ³n o un nuevo estado que se pasa al siguiente paso)
    

---

### ğŸ“‰ Diagrama simplificado:

```
Input_t + Hidden_{t-1} â†’ Hidden_t â†’ Output_t
```

> Es como una conversaciÃ³n:
> 
> - Lo que estÃ¡s escuchando (input_t)
> - Lo que ya sabes (hidden_{t-1})
> - Y lo que concluyes (output_t)

Y luego ese â€œestado internoâ€ se **pasa al siguiente paso**, para que lo que venga **tenga contexto**.

---

### ğŸ“š Ejemplo concreto:

Supongamos que estÃ¡s leyendo:

> â€œEl niÃ±o estaba muy...â€
> 

Y luego viene â€œtristeâ€.

- Si la red sÃ³lo viera â€œtristeâ€, no sabrÃ­a de quiÃ©n estÃ¡ hablando.
- Pero como **recordÃ³ que era â€˜el niÃ±oâ€™**, puede entender el contexto completo.

Eso es lo que permite la **estructura recursiva** de la RNN: **estado que fluye en el tiempo**.

---

### ğŸ§  Â¿QuÃ© significa el â€œestado ocultoâ€?

- Es como una mini memoria interna.
- Guarda lo que la red aprendiÃ³ hasta ahora.
- Y se actualiza **en cada paso**, dependiendo de lo que recibe.

---

### ğŸ¤¯ Â¿QuÃ© lo diferencia realmente de un MLP?

En una **MLP**, si vos le das 10 palabras, ella las procesa **todas juntas, como si fueran independientes**.

En una **RNN**, esas 10 palabras **se procesan en orden**, y lo que la red hace con la palabra nÃºmero 6 **depende de lo que pasÃ³ con la 1, 2, 3...**.

La RNN se convierte asÃ­ en algo muy **cercano al pensamiento humano en lenguaje.**